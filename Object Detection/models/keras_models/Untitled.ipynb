{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'object_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-db66e0b168db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmobilenet_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\models\\SSD-MobileNet\\models\\research\\object_detection\\models\\keras_models\\mobilenet_v1.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/research/object_detection'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfreezable_batch_norm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_models\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'"
     ]
    }
   ],
   "source": [
    "import mobilenet_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"A wrapper around the Keras MobilenetV1 models for object detection.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import sys\n",
    "sys.path.append('models/research/object_detection')\n",
    "from object_detection.core import freezable_batch_norm\n",
    "from object_detection.models.keras_models import model_utils\n",
    "\n",
    "\n",
    "def _fixed_padding(inputs, kernel_size, rate=1):  # pylint: disable=invalid-name\n",
    "  \"\"\"Pads the input along the spatial dimensions independently of input size.\n",
    "\n",
    "  Pads the input such that if it was used in a convolution with 'VALID' padding,\n",
    "  the output would have the same dimensions as if the unpadded input was used\n",
    "  in a convolution with 'SAME' padding.\n",
    "\n",
    "  Args:\n",
    "    inputs: A tensor of size [batch, height_in, width_in, channels].\n",
    "    kernel_size: The kernel to be used in the conv2d or max_pool2d operation.\n",
    "    rate: An integer, rate for atrous convolution.\n",
    "\n",
    "  Returns:\n",
    "    output: A tensor of size [batch, height_out, width_out, channels] with the\n",
    "      input, either intact (if kernel_size == 1) or padded (if kernel_size > 1).\n",
    "  \"\"\"\n",
    "  kernel_size_effective = [kernel_size[0] + (kernel_size[0] - 1) * (rate - 1),\n",
    "                           kernel_size[0] + (kernel_size[0] - 1) * (rate - 1)]\n",
    "  pad_total = [kernel_size_effective[0] - 1, kernel_size_effective[1] - 1]\n",
    "  pad_beg = [pad_total[0] // 2, pad_total[1] // 2]\n",
    "  pad_end = [pad_total[0] - pad_beg[0], pad_total[1] - pad_beg[1]]\n",
    "  padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg[0], pad_end[0]],\n",
    "                                  [pad_beg[1], pad_end[1]], [0, 0]])\n",
    "  return padded_inputs\n",
    "\n",
    "\n",
    "class _LayersOverride(object):\n",
    "  \"\"\"Alternative Keras layers interface for the Keras MobileNetV1.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               batchnorm_training,\n",
    "               default_batchnorm_momentum=0.999,\n",
    "               conv_hyperparams=None,\n",
    "               use_explicit_padding=False,\n",
    "               alpha=1.0,\n",
    "               min_depth=None,\n",
    "               conv_defs=None):\n",
    "    \"\"\"Alternative tf.keras.layers interface, for use by the Keras MobileNetV1.\n",
    "\n",
    "    It is used by the Keras applications kwargs injection API to\n",
    "    modify the MobilenetV1 Keras application with changes required by\n",
    "    the Object Detection API.\n",
    "\n",
    "    These injected interfaces make the following changes to the network:\n",
    "\n",
    "    - Applies the Object Detection hyperparameter configuration\n",
    "    - Supports FreezableBatchNorms\n",
    "    - Adds support for a min number of filters for each layer\n",
    "    - Makes the `alpha` parameter affect the final convolution block even if it\n",
    "        is less than 1.0\n",
    "    - Adds support for explicit padding of convolutions\n",
    "\n",
    "    Args:\n",
    "      batchnorm_training: Bool. Assigned to Batch norm layer `training` param\n",
    "        when constructing `freezable_batch_norm.FreezableBatchNorm` layers.\n",
    "      default_batchnorm_momentum: Float. When 'conv_hyperparams' is None,\n",
    "        batch norm layers will be constructed using this value as the momentum.\n",
    "      conv_hyperparams: A `hyperparams_builder.KerasLayerHyperparams` object\n",
    "        containing hyperparameters for convolution ops. Optionally set to `None`\n",
    "        to use default mobilenet_v1 layer builders.\n",
    "      use_explicit_padding: If True, use 'valid' padding for convolutions,\n",
    "        but explicitly pre-pads inputs so that the output dimensions are the\n",
    "        same as if 'same' padding were used. Off by default.\n",
    "      alpha: The width multiplier referenced in the MobileNetV1 paper. It\n",
    "        modifies the number of filters in each convolutional layer. It's called\n",
    "        depth multiplier in Keras application MobilenetV1.\n",
    "      min_depth: Minimum number of filters in the convolutional layers.\n",
    "      conv_defs: Network layout to specify the mobilenet_v1 body. Default is\n",
    "        `None` to use the default mobilenet_v1 network layout.\n",
    "    \"\"\"\n",
    "    self._alpha = alpha\n",
    "    self._batchnorm_training = batchnorm_training\n",
    "    self._default_batchnorm_momentum = default_batchnorm_momentum\n",
    "    self._conv_hyperparams = conv_hyperparams\n",
    "    self._use_explicit_padding = use_explicit_padding\n",
    "    self._min_depth = min_depth\n",
    "    self._conv_defs = conv_defs\n",
    "    self.regularizer = tf.keras.regularizers.l2(0.00004 * 0.5)\n",
    "    self.initializer = tf.truncated_normal_initializer(stddev=0.09)\n",
    "\n",
    "  def _FixedPaddingLayer(self, kernel_size, rate=1):\n",
    "    return tf.keras.layers.Lambda(\n",
    "        lambda x: _fixed_padding(x, kernel_size, rate))\n",
    "\n",
    "  def Conv2D(self, filters, kernel_size, **kwargs):\n",
    "    \"\"\"Builds a Conv2D layer according to the current Object Detection config.\n",
    "\n",
    "    Overrides the Keras MobileNetV1 application's convolutions with ones that\n",
    "    follow the spec specified by the Object Detection hyperparameters.\n",
    "\n",
    "    Args:\n",
    "      filters: The number of filters to use for the convolution.\n",
    "      kernel_size: The kernel size to specify the height and width of the 2D\n",
    "        convolution window. In this function, the kernel size is expected to\n",
    "        be pair of numbers and the numbers must be equal for this function.\n",
    "      **kwargs: Keyword args specified by the Keras application for\n",
    "        constructing the convolution.\n",
    "\n",
    "    Returns:\n",
    "      A one-arg callable that will either directly apply a Keras Conv2D layer to\n",
    "      the input argument, or that will first pad the input then apply a Conv2D\n",
    "      layer.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: if kernel size is not a pair of equal\n",
    "        integers (representing a square kernel).\n",
    "    \"\"\"\n",
    "    if not isinstance(kernel_size, tuple):\n",
    "      raise ValueError('kernel is expected to be a tuple.')\n",
    "    if len(kernel_size) != 2:\n",
    "      raise ValueError('kernel is expected to be length two.')\n",
    "    if kernel_size[0] != kernel_size[1]:\n",
    "      raise ValueError('kernel is expected to be square.')\n",
    "    layer_name = kwargs['name']\n",
    "    if self._conv_defs:\n",
    "      conv_filters = model_utils.get_conv_def(self._conv_defs, layer_name)\n",
    "      if conv_filters:\n",
    "        filters = conv_filters\n",
    "    # Apply the width multiplier and the minimum depth to the convolution layers\n",
    "    filters = int(filters * self._alpha)\n",
    "    if self._min_depth and filters < self._min_depth:\n",
    "      filters = self._min_depth\n",
    "\n",
    "    if self._conv_hyperparams:\n",
    "      kwargs = self._conv_hyperparams.params(**kwargs)\n",
    "    else:\n",
    "      kwargs['kernel_regularizer'] = self.regularizer\n",
    "      kwargs['kernel_initializer'] = self.initializer\n",
    "\n",
    "    kwargs['padding'] = 'same'\n",
    "    if self._use_explicit_padding and kernel_size[0] > 1:\n",
    "      kwargs['padding'] = 'valid'\n",
    "      def padded_conv(features):  # pylint: disable=invalid-name\n",
    "        padded_features = self._FixedPaddingLayer(kernel_size)(features)\n",
    "        return tf.keras.layers.Conv2D(\n",
    "            filters, kernel_size, **kwargs)(padded_features)\n",
    "      return padded_conv\n",
    "    else:\n",
    "      return tf.keras.layers.Conv2D(filters, kernel_size, **kwargs)\n",
    "\n",
    "  def DepthwiseConv2D(self, kernel_size, **kwargs):\n",
    "    \"\"\"Builds a DepthwiseConv2D according to the Object Detection config.\n",
    "\n",
    "    Overrides the Keras MobileNetV2 application's convolutions with ones that\n",
    "    follow the spec specified by the Object Detection hyperparameters.\n",
    "\n",
    "    Args:\n",
    "      kernel_size: The kernel size to specify the height and width of the 2D\n",
    "        convolution window.\n",
    "      **kwargs: Keyword args specified by the Keras application for\n",
    "        constructing the convolution.\n",
    "\n",
    "    Returns:\n",
    "      A one-arg callable that will either directly apply a Keras DepthwiseConv2D\n",
    "      layer to the input argument, or that will first pad the input then apply\n",
    "      the depthwise convolution.\n",
    "    \"\"\"\n",
    "    if self._conv_hyperparams:\n",
    "      kwargs = self._conv_hyperparams.params(**kwargs)\n",
    "      # Both regularizer and initializaer also applies to depthwise layer in\n",
    "      # MobilenetV1, so we remap the kernel_* to depthwise_* here.\n",
    "      kwargs['depthwise_regularizer'] = kwargs['kernel_regularizer']\n",
    "      kwargs['depthwise_initializer'] = kwargs['kernel_initializer']\n",
    "    else:\n",
    "      kwargs['depthwise_regularizer'] = self.regularizer\n",
    "      kwargs['depthwise_initializer'] = self.initializer\n",
    "\n",
    "    kwargs['padding'] = 'same'\n",
    "    if self._use_explicit_padding:\n",
    "      kwargs['padding'] = 'valid'\n",
    "      def padded_depthwise_conv(features):  # pylint: disable=invalid-name\n",
    "        padded_features = self._FixedPaddingLayer(kernel_size)(features)\n",
    "        return tf.keras.layers.DepthwiseConv2D(\n",
    "            kernel_size, **kwargs)(padded_features)\n",
    "      return padded_depthwise_conv\n",
    "    else:\n",
    "      return tf.keras.layers.DepthwiseConv2D(kernel_size, **kwargs)\n",
    "\n",
    "  def BatchNormalization(self, **kwargs):\n",
    "    \"\"\"Builds a normalization layer.\n",
    "\n",
    "    Overrides the Keras application batch norm with the norm specified by the\n",
    "    Object Detection configuration.\n",
    "\n",
    "    Args:\n",
    "      **kwargs: Only the name is used, all other params ignored.\n",
    "        Required for matching `layers.BatchNormalization` calls in the Keras\n",
    "        application.\n",
    "\n",
    "    Returns:\n",
    "      A normalization layer specified by the Object Detection hyperparameter\n",
    "      configurations.\n",
    "    \"\"\"\n",
    "    name = kwargs.get('name')\n",
    "    if self._conv_hyperparams:\n",
    "      return self._conv_hyperparams.build_batch_norm(\n",
    "          training=self._batchnorm_training,\n",
    "          name=name)\n",
    "    else:\n",
    "      return freezable_batch_norm.FreezableBatchNorm(\n",
    "          training=self._batchnorm_training,\n",
    "          epsilon=1e-3,\n",
    "          momentum=self._default_batchnorm_momentum,\n",
    "          name=name)\n",
    "\n",
    "  def Input(self, shape):\n",
    "    \"\"\"Builds an Input layer.\n",
    "\n",
    "    Overrides the Keras application Input layer with one that uses a\n",
    "    tf.placeholder_with_default instead of a tf.placeholder. This is necessary\n",
    "    to ensure the application works when run on a TPU.\n",
    "\n",
    "    Args:\n",
    "      shape: The shape for the input layer to use. (Does not include a dimension\n",
    "        for the batch size).\n",
    "    Returns:\n",
    "      An input layer for the specified shape that internally uses a\n",
    "      placeholder_with_default.\n",
    "    \"\"\"\n",
    "    default_size = 224\n",
    "    default_batch_size = 1\n",
    "    shape = list(shape)\n",
    "    default_shape = [default_size if dim is None else dim for dim in shape]\n",
    "\n",
    "    input_tensor = tf.constant(0.0, shape=[default_batch_size] + default_shape)\n",
    "\n",
    "    placeholder_with_default = tf.placeholder_with_default(\n",
    "        input=input_tensor, shape=[None] + shape)\n",
    "    return model_utils.input_layer(shape, placeholder_with_default)\n",
    "\n",
    "  # pylint: disable=unused-argument\n",
    "  def ReLU(self, *args, **kwargs):\n",
    "    \"\"\"Builds an activation layer.\n",
    "\n",
    "    Overrides the Keras application ReLU with the activation specified by the\n",
    "    Object Detection configuration.\n",
    "\n",
    "    Args:\n",
    "      *args: Ignored, required to match the `tf.keras.ReLU` interface\n",
    "      **kwargs: Only the name is used,\n",
    "        required to match `tf.keras.ReLU` interface\n",
    "\n",
    "    Returns:\n",
    "      An activation layer specified by the Object Detection hyperparameter\n",
    "      configurations.\n",
    "    \"\"\"\n",
    "    name = kwargs.get('name')\n",
    "    if self._conv_hyperparams:\n",
    "      return self._conv_hyperparams.build_activation_layer(name=name)\n",
    "    else:\n",
    "      return tf.keras.layers.Lambda(tf.nn.relu6, name=name)\n",
    "  # pylint: enable=unused-argument\n",
    "\n",
    "  # pylint: disable=unused-argument\n",
    "  def ZeroPadding2D(self, padding, **kwargs):\n",
    "    \"\"\"Replaces explicit padding in the Keras application with a no-op.\n",
    "\n",
    "    Args:\n",
    "      padding: The padding values for image height and width.\n",
    "      **kwargs: Ignored, required to match the Keras applications usage.\n",
    "\n",
    "    Returns:\n",
    "      A no-op identity lambda.\n",
    "    \"\"\"\n",
    "    return lambda x: x\n",
    "  # pylint: enable=unused-argument\n",
    "\n",
    "  # Forward all non-overridden methods to the keras layers\n",
    "  def __getattr__(self, item):\n",
    "    return getattr(tf.keras.layers, item)\n",
    "\n",
    "\n",
    "# pylint: disable=invalid-name\n",
    "def mobilenet_v1(batchnorm_training,\n",
    "                 default_batchnorm_momentum=0.9997,\n",
    "                 conv_hyperparams=None,\n",
    "                 use_explicit_padding=False,\n",
    "                 alpha=1.0,\n",
    "                 min_depth=None,\n",
    "                 conv_defs=None,\n",
    "                 **kwargs):\n",
    "  \"\"\"Instantiates the MobileNetV1 architecture, modified for object detection.\n",
    "\n",
    "  This wraps the MobileNetV1 tensorflow Keras application, but uses the\n",
    "  Keras application's kwargs-based monkey-patching API to override the Keras\n",
    "  architecture with the following changes:\n",
    "\n",
    "  - Changes the default batchnorm momentum to 0.9997\n",
    "  - Applies the Object Detection hyperparameter configuration\n",
    "  - Supports FreezableBatchNorms\n",
    "  - Adds support for a min number of filters for each layer\n",
    "  - Makes the `alpha` parameter affect the final convolution block even if it\n",
    "      is less than 1.0\n",
    "  - Adds support for explicit padding of convolutions\n",
    "  - Makes the Input layer use a tf.placeholder_with_default instead of a\n",
    "      tf.placeholder, to work on TPUs.\n",
    "\n",
    "  Args:\n",
    "      batchnorm_training: Bool. Assigned to Batch norm layer `training` param\n",
    "        when constructing `freezable_batch_norm.FreezableBatchNorm` layers.\n",
    "      default_batchnorm_momentum: Float. When 'conv_hyperparams' is None,\n",
    "        batch norm layers will be constructed using this value as the momentum.\n",
    "      conv_hyperparams: A `hyperparams_builder.KerasLayerHyperparams` object\n",
    "        containing hyperparameters for convolution ops. Optionally set to `None`\n",
    "        to use default mobilenet_v1 layer builders.\n",
    "      use_explicit_padding: If True, use 'valid' padding for convolutions,\n",
    "        but explicitly pre-pads inputs so that the output dimensions are the\n",
    "        same as if 'same' padding were used. Off by default.\n",
    "      alpha: The width multiplier referenced in the MobileNetV1 paper. It\n",
    "        modifies the number of filters in each convolutional layer.\n",
    "      min_depth: Minimum number of filters in the convolutional layers.\n",
    "      conv_defs: Network layout to specify the mobilenet_v1 body. Default is\n",
    "        `None` to use the default mobilenet_v1 network layout.\n",
    "      **kwargs: Keyword arguments forwarded directly to the\n",
    "        `tf.keras.applications.Mobilenet` method that constructs the Keras\n",
    "        model.\n",
    "\n",
    "  Returns:\n",
    "      A Keras model instance.\n",
    "  \"\"\"\n",
    "  layers_override = _LayersOverride(\n",
    "      batchnorm_training,\n",
    "      default_batchnorm_momentum=default_batchnorm_momentum,\n",
    "      conv_hyperparams=conv_hyperparams,\n",
    "      use_explicit_padding=use_explicit_padding,\n",
    "      min_depth=min_depth,\n",
    "      alpha=alpha,\n",
    "      conv_defs=conv_defs)\n",
    "  return tf.keras.applications.MobileNet(\n",
    "      alpha=alpha, layers=layers_override, **kwargs)\n",
    "# pylint: enable=invalid-name\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
